# å®˜æ–¹æ•™ç¨‹
[å®˜æ–¹æ•™ç¨‹](https://superset.incubator.apache.org/)
1. æ”¯æŒ3.6ç‰ˆæœ¬ä»¥ä¸Šçš„pythonï¼ˆå»ºè®®åœ¨æ–°çš„è™šæ‹Ÿç¯å¢ƒä¸­æ“ä½œï¼‰  
2. å‡çº§å®‰è£…å·¥å…·  
```
pip install â€“upgrade setuptools pip
```
3. å®‰è£…ç›¸åº”çš„åº“[requirement](./superset_requirement.txt)  
```
pip install -r requirements.txt
```
4. å®‰è£…superset  
```
pip install superset
```
5. åˆ›å»ºç®¡ç†å¸æˆ·
```
$ export FLASK_APP=superset
flask fab create-admin
```
6. åŠ è½½ä¾‹å­æ•°æ®  
```
superset load_examples
```
7. åˆ›å»ºè§’è‰²å’Œæƒé™
```
superset init
```
8. å¼€å¯superset
```
superset run -p 8080 --with-threads --reload --debugger
```
# ä¸‰æ–¹pythonåŒ…åŠè¿æ¥urlå‰ç¼€

|Database|Package|SQLAlchemy URI prefix|
|  ----  | ----  | ----  |
|database|pypi package|SQLAlchemy URI prefix|
|MySQL|pip install mysqlclient|mysql://|
|Postgres|pip install psycopg2|postgresql+psycopg2://|
|Presto|pip install pyhive|presto://|
|Hive|pip install pyhive|hive://|
|Oracle|pip install cx_Oracle|oracle://|
|sqlite||sqlite://|
|Snowflake|pip install snowflake-sqlalchemy|snowflake://|
|Redshift|pip install sqlalchemy-redshift|redshift+psycopg2://|
|MSSQL|pip install pymssql|mssql://|
|Impala|pip install impyla|impala://|
|SparkSQL|pip install pyhive|jdbc+hive://|
|Greenplum|pip install psycopg2|postgresql+psycopg2://|
|Athena|pip install "PyAthenaJDBC>1.0.9"|awsathena+jdbc://|
|Athena|pip install "PyAthena>1.2.0"|awsathena+rest://|
|Vertica|pip install sqlalchemy-vertica-python|vertica+vertica_python://|
|ClickHouse|pip install sqlalchemy-clickhouse|clickhouse://|
|Kylin|pip install kylinpy|kylin://|
|BigQuery|pip install pybigquery|bigquery://|
|Teradata|pip install sqlalchemy-teradata|teradata://|
|Pinot|pip install pinotdb|pinot+http://controller:5436/ query?server=http://controller:5983/|

# åˆ†äº«å›¾è¡¨ä¸éœ€è¦ç™»é™†å³å¯æŸ¥çœ‹
+ /superset/config.pyç¬¬127è¡Œ
```
# ---------------------------------------------------
# Roles config
# ---------------------------------------------------
# Grant public role the same set of permissions as for the GAMMA role.
# This is useful if one wants to enable anonymous users to view
# dashboards. Explicit grant on specific datasets is still required.
PUBLIC_ROLE_LIKE_GAMMA = False
```
>å°†PUBLIC_ROLE_LIKE_GAMMAæ”¹ä¸ºTrueï¼Œ  
ã€æ³¨é‡Šæ„æ€ã€‘  
æˆäºˆå…¬å…±è§’è‰²ä¸GAMMAè§’è‰²ç›¸åŒçš„æƒé™é›†ã€‚  
å¦‚æœæƒ³è®©åŒ¿åç”¨æˆ·æŸ¥çœ‹ï¼Œå¯ä»¥è®¾ç½®è¿™é‡Œ  
åœ¨ä»ªè¡¨ç›˜å¯¹ç‰¹å®šæ•°æ®é›†çš„æˆæƒæ˜¾ç¤ºï¼Œä¹Ÿåœ¨è¿™é‡Œè®¾ç½®ã€‚  
+ åŠ å…¥æ•°æ®åº“æƒé™è¿™é‡ŒåŠ å…¥æ‰€æœ‰æ•°æ®åº“æƒé™  
>å®‰å…¨ ğŸ‘‰ è§’è‰²åˆ—è¡¨ ğŸ‘‰ Public ğŸ‘‰ ç¼–è¾‘è®°å½•  
>>can explore on Supersetä¸ºå¯¼å‡ºå›¾è¡¨  
can explore json on Supersetä¸ºå¯¼å‡ºå›¾è¡¨json  
all database access on all_database_accessè®¿é—®æ‰€æœ‰æ•°æ®åº“æƒé™ï¼Œä¹Ÿå¯ä»¥è®¾ç½®å•ä¸ª  
  
# MAXBOXé…ç½®
+ ç”³è¯·key  
[MAPBOX](https://account.mapbox.com/)
+ ä¿®æ”¹superseté…ç½®(\superset\Lib\site-packages\superset\config.py)
```
# Set this API key to enable Mapbox visualizations
# MAPBOX_API_KEY = os.environ.get('MAPBOX_API_KEY', '')
MAPBOX_API_KEY = 'pk.eyJâ€¦'
```

#Error
## Error1
+ è¿è¡Œ ```$ fabmanager create-admin --app superset æç¤ºé”™è¯¯ Was unable to import superset Error: cannot import name 'quoted_name'```
+ è§£å†³æ–¹æ¡ˆï¼š  
```pip install -r requirements.txt```

## Error2
+ æç¤º
```
"Can't determine which FROM clause to join "
sqlalchemy.exc.InvalidRequestError: Can't determine which FROM clause to join from, there are multiple FROMS which can join to this entity. Try adding an explicit ON clause to help resolve the ambiguity.
```
+ è§£å†³æ–¹æ¡ˆ
```
pip install sqlalchemy==1.2.18
python superset db upgrad
```

## Error3
+ æç¤º   
```
(superset) [root@superset opt]# fabmanager create-admin --app superset
Username [admin]: admin
User first name [admin]: admin
User last name [user]: admin
Email [admin@fab.org]: admin@qq.com
Password:
Repeat for confirmation:
Was unable to import superset Error: cannot import name '_maybe_box_datetimelike'
```
+ è§£å†³æ–¹æ¡ˆ   
```
pip install pandas==0.23.4
```

## Error4
+ ```module â€˜signalâ€™ has no attribute 'SIGALRM'```
+ è§£å†³æ–¹æ¡ˆï¼šæ³¨é‡Šutils.pyä¸­ç±»timeoutå‡½æ•°çš„__enter__ï¼Œå¹¶å¢åŠ pass
```
class timeout(object):
"""
To be used in a ``with`` block and timeout its content.
"""

def __init__(self, seconds=1, error_message='Timeout'):
    self.seconds = seconds
    self.error_message = error_message

def handle_timeout(self, signum, frame):
    logging.error('Process timed out')
    raise SupersetTimeoutException(self.error_message)

def __enter__(self):
    try:
        # signal.signal(signal.SIGALRM, self.handle_timeout)
        # signal.alarm(self.seconds)
        pass
    except ValueError as e:
        logging.warning("timeout can't be used in the current context")
        logging.exception(e)

def __exit__(self, type, value, traceback):
    try:
        # signal.alarm(0)
        pass
    except ValueError as e:
        logging.warning("timeout can't be used in the current context")
        logging.exception(e)
```

## Error5
+ supersetä¸redshiftå…¼å®¹æ€§é—®é¢˜ï¼ˆç”±äºredshifté€šè¿‡sqlæŸ¥è¯¢å¤§å†™å˜æˆå°å†™ï¼Œå¯¼è‡´pandas keyerrorï¼‰  

+ è§£å†³æ–¹æ¡ˆä¸€ï¼šä¿®æ”¹ä»£ç 

```superset\viz.py```ä¸­çš„```get_data```å‡½æ•°
```
def get_data(self, df):
    if (
            self.form_data.get('granularity') == 'all' and
            DTTM_ALIAS in df):
        del df[DTTM_ALIAS]
    try:
        df = df.pivot_table(
            index=self.form_data.get('groupby'),
            columns=self.form_data.get('columns'),
            values=[self.get_metric_label(m) for m in self.form_data.get('metrics')],
            aggfunc=self.form_data.get('pandas_aggfunc'),
            margins=self.form_data.get('pivot_margins'),
        )
    except: #è§£å†³redshiftæŸ¥è¯¢ååˆ—åå˜å°å†™çš„é—®é¢˜
        df = df.pivot_table(
            index=self.form_data.get('groupby'),
            columns=self.form_data.get('columns'),
            values=[self.get_metric_label(m).lower() for m in self.form_data.get('metrics')],
            aggfunc=self.form_data.get('pandas_aggfunc'),
            margins=self.form_data.get('pivot_margins'),
        )
    # Display metrics side by side with each column
    if self.form_data.get('combine_metric'):
        df = df.stack(0).unstack()
    return dict(
        columns=list(df.columns),
        html=df.to_html(
            na_rep='',
            classes=(
                'dataframe table table-striped table-bordered '
                'table-condensed table-hover').split(' ')),
    )
```

+ è§£å†³æ–¹æ¡ˆ2   
>[https://github.com/apache/incubator-superset/issues/5308](https://github.com/apache/incubator-superset/issues/5308)
+ è§£å†³æ–¹æ¡ˆ3   
>ä½¿ç”¨çš„æ—¶å€™åœ¨ç½‘é¡µç«¯ç”Ÿæˆå­—æ®µ Datasource ğŸ‘‰ Metrics ğŸ‘‰ Labelã€ä½¿ç”¨å°å†™çš„åå­—ã€‘

## Error6
+ ```Failed building wheel for sasl```
+ è§£å†³æ–¹æ¡ˆ
æ‰§è¡Œä»¥ä¸‹å‘½ä»¤è§£å†³ï¼š
```sudo apt-get install libsasl2-dev```

## Error7
+ é—®é¢˜
```
error: could not create 'build\bdist.win-amd64\wheel.\superset\static\assets\dist\vendors-deckgl\
layers\arc-deckgl\layers\geojson-deckgl\layers\grid-deckgl\layers\hex-deckgl\layers
\p-39b91eb9.81565bc93ff56be4e334.chunk.js': No such file or directory
```
+ è§£å†³æ–¹æ¡ˆ
```
set TMPDIR=d:\tmp
```